{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wasserstein autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['TEFF', 'LOGG', 'LOG10VDOP', 'METALS', 'C', 'N', 'O Mg Si S Ca Ti'], ['C', 'N', 'O', 'Na', 'Mg', 'Al', 'Si', 'S', 'K', 'Ca', 'Ti', 'V', 'Mn', 'Fe', 'Ni'], ['[C/M]', '[N/M]', '[O/M]', '[Na/H]', '[Mg/M]', '[Al/H]', '[Si/M]', '[S/M]', '[K/H]', '[Ca/M]', '[Ti/M]', '[V/H]', '[Mn/H]', '[Fe/H]', '[Ni/H]'], [0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1])]\n"
     ]
    }
   ],
   "source": [
    "import apogee.tools.read as apread\n",
    "import matplotlib.pyplot as plt \n",
    "import apogee.tools.path as apogee_path\n",
    "from apogee.tools import bitmask\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.autograd as autograd\n",
    "\n",
    "\n",
    "from apoNN.src.datasets import ApogeeDataset,AspcapDataset\n",
    "from apoNN.src.utils import get_mask_elem,dump,load,generate_loss_with_masking\n",
    "\n",
    "import apoNN.src.vectors as vector\n",
    "\n",
    "\n",
    "from tagging.src.networks import ConditioningAutoencoder,Embedding_Decoder,Feedforward,ParallelDecoder,Autoencoder,Discriminator\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "apogee_path.change_dr(16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"aspcap_training_clean\"\n",
    "recenter=True\n",
    "n_bins = 8575\n",
    "n_z = 16\n",
    "n_shared = 5\n",
    "activation = nn.LeakyReLU()\n",
    "lr = 0.0001\n",
    "n_batch = 64\n",
    "lambda_fact = 0.01\n",
    "encoder_architecture = [n_bins,1024,512,128,n_z]\n",
    "decoder_architecture = [n_z,128,512,1024,n_bins]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = AspcapDataset(filename=dataset_name,recenter=recenter)\n",
    "dataset_occam = AspcapDataset(filename=\"aspcap_occam\",recenter=True,tensor_type=torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = torch.utils.data.DataLoader(dataset = dataset,\n",
    "                                     batch_size = n_batch,\n",
    "                                     shuffle= True,\n",
    "                                     drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Feedforward([n_bins,512,128,32,n_z],activation=nn.SELU()).to(device)\n",
    "decoder = Feedforward([n_z,512,128,n_bins],activation=nn.SELU()).to(device)\n",
    "autoencoder = Autoencoder(encoder,decoder,n_bins=n_bins).to(device)\n",
    "\n",
    "discriminator = Feedforward([n_z,512,256,128,32,1],activation=nn.SELU()).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()\n",
    "\n",
    "lambda_gp = 10\n",
    "n_critic = 10\n",
    "optimizer_G = torch.optim.Adam(autoencoder.parameters(), lr=lr)\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr)\n",
    "\n",
    "Tensor = torch.FloatTensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_gradient_penalty(D, real_samples, fake_samples):\n",
    "    \"\"\"Calculates the gradient penalty loss for WGAN GP\"\"\"\n",
    "    # Random weight term for interpolation between real and fake samples\n",
    "    alpha = Tensor(np.random.random((real_samples.size(0), 1)))\n",
    "    # Get random interpolation between real and fake samples\n",
    "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
    "    d_interpolates = D(interpolates)\n",
    "    fake = Variable(Tensor(real_samples.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "    # Get gradient w.r.t. interpolates\n",
    "    gradients = autograd.grad(\n",
    "        outputs=d_interpolates,\n",
    "        inputs=interpolates,\n",
    "        grad_outputs=fake,\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True,\n",
    "    )[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/100] [Batch 0/312] [D: -2.759662] [G: 22.521971] [R: 0.004683]\n",
      "[Epoch 0/100] [Batch 30/312] [D: -2.822412] [G: 22.672064] [R: 0.005414]\n",
      "[Epoch 0/100] [Batch 60/312] [D: -2.910625] [G: 22.594885] [R: 0.005227]\n",
      "[Epoch 0/100] [Batch 90/312] [D: -2.537907] [G: 22.725121] [R: 0.003325]\n",
      "[Epoch 0/100] [Batch 120/312] [D: -2.708971] [G: 22.738150] [R: 0.003593]\n",
      "[Epoch 0/100] [Batch 150/312] [D: -2.911098] [G: 22.904018] [R: 0.004019]\n",
      "[Epoch 0/100] [Batch 180/312] [D: -2.333395] [G: 23.335079] [R: 0.003971]\n",
      "[Epoch 0/100] [Batch 210/312] [D: -2.454134] [G: 23.439220] [R: 0.005647]\n",
      "[Epoch 0/100] [Batch 240/312] [D: -2.362751] [G: 23.858459] [R: 0.005163]\n",
      "[Epoch 0/100] [Batch 270/312] [D: -2.454611] [G: 23.646284] [R: 0.005349]\n",
      "[Epoch 0/100] [Batch 300/312] [D: -2.597310] [G: 23.421215] [R: 0.004245]\n",
      "[Epoch 1/100] [Batch 0/312] [D: -2.396061] [G: 23.530632] [R: 0.003556]\n",
      "[Epoch 1/100] [Batch 30/312] [D: -2.736678] [G: 23.075911] [R: 0.003274]\n",
      "[Epoch 1/100] [Batch 60/312] [D: -2.402728] [G: 23.244400] [R: 0.002907]\n",
      "[Epoch 1/100] [Batch 90/312] [D: -2.754789] [G: 23.139050] [R: 0.002422]\n",
      "[Epoch 1/100] [Batch 120/312] [D: -2.735198] [G: 22.951530] [R: 0.003414]\n",
      "[Epoch 1/100] [Batch 150/312] [D: -2.471519] [G: 22.906403] [R: 0.003530]\n",
      "[Epoch 1/100] [Batch 180/312] [D: -2.300656] [G: 23.171322] [R: 0.004437]\n",
      "[Epoch 1/100] [Batch 210/312] [D: -2.537297] [G: 23.561937] [R: 0.004505]\n",
      "[Epoch 1/100] [Batch 240/312] [D: -2.359872] [G: 23.767897] [R: 0.004297]\n",
      "[Epoch 1/100] [Batch 270/312] [D: -2.572520] [G: 23.705015] [R: 0.002779]\n",
      "[Epoch 1/100] [Batch 300/312] [D: -2.267343] [G: 23.977936] [R: 0.003344]\n",
      "[Epoch 2/100] [Batch 0/312] [D: -2.326099] [G: 23.961876] [R: 0.002632]\n",
      "[Epoch 2/100] [Batch 30/312] [D: -2.407396] [G: 23.331541] [R: 0.002481]\n",
      "[Epoch 2/100] [Batch 60/312] [D: -2.858951] [G: 23.320774] [R: 0.002520]\n",
      "[Epoch 2/100] [Batch 90/312] [D: -2.554511] [G: 23.930471] [R: 0.002107]\n",
      "[Epoch 2/100] [Batch 120/312] [D: -2.567553] [G: 23.804501] [R: 0.002236]\n",
      "[Epoch 2/100] [Batch 150/312] [D: -2.165036] [G: 24.254454] [R: 0.002630]\n",
      "[Epoch 2/100] [Batch 180/312] [D: -2.343573] [G: 24.483383] [R: 0.002768]\n",
      "[Epoch 2/100] [Batch 210/312] [D: -2.277894] [G: 24.552780] [R: 0.002989]\n",
      "[Epoch 2/100] [Batch 240/312] [D: -2.500340] [G: 24.900511] [R: 0.002602]\n",
      "[Epoch 2/100] [Batch 270/312] [D: -2.353352] [G: 24.901014] [R: 0.002742]\n",
      "[Epoch 2/100] [Batch 300/312] [D: -2.717656] [G: 24.579407] [R: 0.001977]\n",
      "[Epoch 3/100] [Batch 0/312] [D: -2.513036] [G: 24.498016] [R: 0.002253]\n",
      "[Epoch 3/100] [Batch 30/312] [D: -2.490481] [G: 24.370802] [R: 0.002351]\n",
      "[Epoch 3/100] [Batch 60/312] [D: -2.583499] [G: 24.453335] [R: 0.002189]\n",
      "[Epoch 3/100] [Batch 90/312] [D: -2.244330] [G: 24.741344] [R: 0.002503]\n",
      "[Epoch 3/100] [Batch 120/312] [D: -2.217799] [G: 24.733343] [R: 0.002625]\n",
      "[Epoch 3/100] [Batch 150/312] [D: -2.245788] [G: 24.655725] [R: 0.002173]\n",
      "[Epoch 3/100] [Batch 180/312] [D: -2.043000] [G: 24.789986] [R: 0.002492]\n",
      "[Epoch 3/100] [Batch 210/312] [D: -2.359942] [G: 24.636646] [R: 0.002293]\n",
      "[Epoch 3/100] [Batch 240/312] [D: -2.494282] [G: 24.732258] [R: 0.002701]\n",
      "[Epoch 3/100] [Batch 270/312] [D: -2.342376] [G: 24.851347] [R: 0.002996]\n",
      "[Epoch 3/100] [Batch 300/312] [D: -2.513617] [G: 24.668289] [R: 0.003178]\n",
      "[Epoch 4/100] [Batch 0/312] [D: -2.327811] [G: 25.008173] [R: 0.004141]\n",
      "[Epoch 4/100] [Batch 30/312] [D: -2.223879] [G: 25.382990] [R: 0.005040]\n",
      "[Epoch 4/100] [Batch 60/312] [D: -2.408192] [G: 25.264843] [R: 0.004885]\n",
      "[Epoch 4/100] [Batch 90/312] [D: -2.325995] [G: 25.382513] [R: 0.003474]\n",
      "[Epoch 4/100] [Batch 120/312] [D: -2.645822] [G: 24.474472] [R: 0.003060]\n",
      "[Epoch 4/100] [Batch 150/312] [D: -2.700325] [G: 24.370607] [R: 0.003677]\n",
      "[Epoch 4/100] [Batch 180/312] [D: -2.745798] [G: 24.157488] [R: 0.002529]\n",
      "[Epoch 4/100] [Batch 210/312] [D: -2.884613] [G: 24.088608] [R: 0.002322]\n",
      "[Epoch 4/100] [Batch 240/312] [D: -2.562890] [G: 24.297775] [R: 0.002920]\n",
      "[Epoch 4/100] [Batch 270/312] [D: -2.390723] [G: 24.294722] [R: 0.002561]\n",
      "[Epoch 4/100] [Batch 300/312] [D: -2.397732] [G: 24.095642] [R: 0.002572]\n",
      "[Epoch 5/100] [Batch 0/312] [D: -2.527863] [G: 24.299128] [R: 0.002665]\n",
      "[Epoch 5/100] [Batch 30/312] [D: -2.291463] [G: 24.038338] [R: 0.002938]\n",
      "[Epoch 5/100] [Batch 60/312] [D: -2.445982] [G: 24.195913] [R: 0.002958]\n",
      "[Epoch 5/100] [Batch 90/312] [D: -2.618423] [G: 24.121971] [R: 0.002581]\n",
      "[Epoch 5/100] [Batch 120/312] [D: -2.774223] [G: 23.663063] [R: 0.002211]\n",
      "[Epoch 5/100] [Batch 150/312] [D: -2.784140] [G: 23.702332] [R: 0.001699]\n",
      "[Epoch 5/100] [Batch 180/312] [D: -2.625926] [G: 23.490362] [R: 0.001797]\n",
      "[Epoch 5/100] [Batch 210/312] [D: -2.476477] [G: 23.919521] [R: 0.001625]\n",
      "[Epoch 5/100] [Batch 240/312] [D: -2.361292] [G: 23.903215] [R: 0.001522]\n",
      "[Epoch 5/100] [Batch 270/312] [D: -2.466036] [G: 24.124123] [R: 0.001954]\n",
      "[Epoch 5/100] [Batch 300/312] [D: -2.515097] [G: 24.421581] [R: 0.001711]\n",
      "[Epoch 6/100] [Batch 0/312] [D: -2.306222] [G: 24.548615] [R: 0.002310]\n",
      "[Epoch 6/100] [Batch 30/312] [D: -2.612437] [G: 24.339836] [R: 0.002007]\n",
      "[Epoch 6/100] [Batch 60/312] [D: -2.509622] [G: 24.465065] [R: 0.002917]\n",
      "[Epoch 6/100] [Batch 90/312] [D: -2.672159] [G: 24.220018] [R: 0.001522]\n",
      "[Epoch 6/100] [Batch 120/312] [D: -2.424554] [G: 24.435736] [R: 0.002296]\n",
      "[Epoch 6/100] [Batch 150/312] [D: -3.002493] [G: 23.817081] [R: 0.001783]\n",
      "[Epoch 6/100] [Batch 180/312] [D: -2.554435] [G: 24.319025] [R: 0.002102]\n",
      "[Epoch 6/100] [Batch 210/312] [D: -2.666310] [G: 24.268837] [R: 0.002218]\n",
      "[Epoch 6/100] [Batch 240/312] [D: -2.698994] [G: 24.619766] [R: 0.001594]\n",
      "[Epoch 6/100] [Batch 270/312] [D: -2.518115] [G: 24.435764] [R: 0.001955]\n",
      "[Epoch 6/100] [Batch 300/312] [D: -2.427413] [G: 24.653938] [R: 0.001402]\n",
      "[Epoch 7/100] [Batch 0/312] [D: -2.531839] [G: 24.638578] [R: 0.001564]\n",
      "[Epoch 7/100] [Batch 30/312] [D: -2.364929] [G: 24.633770] [R: 0.002564]\n",
      "[Epoch 7/100] [Batch 60/312] [D: -2.256580] [G: 25.054417] [R: 0.001943]\n",
      "[Epoch 7/100] [Batch 90/312] [D: -2.347748] [G: 25.028496] [R: 0.001733]\n",
      "[Epoch 7/100] [Batch 120/312] [D: -2.714358] [G: 24.778812] [R: 0.001664]\n",
      "[Epoch 7/100] [Batch 150/312] [D: -2.574386] [G: 24.757992] [R: 0.001733]\n",
      "[Epoch 7/100] [Batch 180/312] [D: -2.566265] [G: 24.352913] [R: 0.001641]\n",
      "[Epoch 7/100] [Batch 210/312] [D: -2.516804] [G: 24.340458] [R: 0.001737]\n",
      "[Epoch 7/100] [Batch 240/312] [D: -2.338151] [G: 24.369936] [R: 0.001858]\n",
      "[Epoch 7/100] [Batch 270/312] [D: -2.102659] [G: 25.027100] [R: 0.001640]\n",
      "[Epoch 7/100] [Batch 300/312] [D: -2.233829] [G: 24.922821] [R: 0.002029]\n",
      "[Epoch 8/100] [Batch 0/312] [D: -2.390367] [G: 24.785332] [R: 0.001502]\n",
      "[Epoch 8/100] [Batch 30/312] [D: -2.112385] [G: 25.088993] [R: 0.002812]\n",
      "[Epoch 8/100] [Batch 60/312] [D: -2.278210] [G: 25.070578] [R: 0.001488]\n",
      "[Epoch 8/100] [Batch 90/312] [D: -2.248676] [G: 25.256527] [R: 0.001477]\n",
      "[Epoch 8/100] [Batch 120/312] [D: -2.273183] [G: 25.524916] [R: 0.001399]\n",
      "[Epoch 8/100] [Batch 150/312] [D: -2.405016] [G: 25.214649] [R: 0.001127]\n",
      "[Epoch 8/100] [Batch 180/312] [D: -2.397421] [G: 24.819628] [R: 0.001453]\n",
      "[Epoch 8/100] [Batch 210/312] [D: -2.419713] [G: 25.264292] [R: 0.001308]\n",
      "[Epoch 8/100] [Batch 240/312] [D: -2.375217] [G: 25.210670] [R: 0.001272]\n",
      "[Epoch 8/100] [Batch 270/312] [D: -2.480620] [G: 25.276897] [R: 0.001308]\n",
      "[Epoch 8/100] [Batch 300/312] [D: -2.511343] [G: 24.993614] [R: 0.001513]\n",
      "[Epoch 9/100] [Batch 0/312] [D: -2.334715] [G: 25.155844] [R: 0.001193]\n",
      "[Epoch 9/100] [Batch 30/312] [D: -2.594936] [G: 24.879118] [R: 0.001259]\n",
      "[Epoch 9/100] [Batch 60/312] [D: -2.633948] [G: 25.066830] [R: 0.001056]\n",
      "[Epoch 9/100] [Batch 90/312] [D: -2.623306] [G: 24.634218] [R: 0.001109]\n",
      "[Epoch 9/100] [Batch 120/312] [D: -2.579042] [G: 24.794044] [R: 0.000939]\n",
      "[Epoch 9/100] [Batch 150/312] [D: -2.582333] [G: 24.650845] [R: 0.000866]\n",
      "[Epoch 9/100] [Batch 180/312] [D: -2.422796] [G: 24.637623] [R: 0.000871]\n",
      "[Epoch 9/100] [Batch 210/312] [D: -2.649887] [G: 24.423187] [R: 0.000872]\n",
      "[Epoch 9/100] [Batch 240/312] [D: -2.739332] [G: 24.355942] [R: 0.000990]\n",
      "[Epoch 9/100] [Batch 270/312] [D: -2.665086] [G: 24.464584] [R: 0.000918]\n",
      "[Epoch 9/100] [Batch 300/312] [D: -2.481099] [G: 24.586887] [R: 0.000975]\n",
      "[Epoch 10/100] [Batch 0/312] [D: -2.607694] [G: 24.131201] [R: 0.000819]\n",
      "[Epoch 10/100] [Batch 30/312] [D: -2.413766] [G: 24.439133] [R: 0.001009]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10/100] [Batch 60/312] [D: -2.315536] [G: 24.650448] [R: 0.000868]\n",
      "[Epoch 10/100] [Batch 90/312] [D: -2.561962] [G: 24.582718] [R: 0.000964]\n",
      "[Epoch 10/100] [Batch 120/312] [D: -2.482115] [G: 24.680870] [R: 0.000806]\n",
      "[Epoch 10/100] [Batch 150/312] [D: -2.390168] [G: 24.708462] [R: 0.001008]\n",
      "[Epoch 10/100] [Batch 180/312] [D: -2.503092] [G: 24.236794] [R: 0.000868]\n",
      "[Epoch 10/100] [Batch 210/312] [D: -2.263767] [G: 24.545677] [R: 0.000918]\n",
      "[Epoch 10/100] [Batch 240/312] [D: -2.380030] [G: 24.504097] [R: 0.000865]\n",
      "[Epoch 10/100] [Batch 270/312] [D: -2.175001] [G: 24.648510] [R: 0.001379]\n",
      "[Epoch 10/100] [Batch 300/312] [D: -2.193748] [G: 24.694887] [R: 0.000990]\n",
      "[Epoch 11/100] [Batch 0/312] [D: -2.379736] [G: 24.625546] [R: 0.001109]\n",
      "[Epoch 11/100] [Batch 30/312] [D: -2.587322] [G: 24.050076] [R: 0.000997]\n",
      "[Epoch 11/100] [Batch 60/312] [D: -2.359738] [G: 24.123186] [R: 0.001065]\n",
      "[Epoch 11/100] [Batch 90/312] [D: -2.514921] [G: 23.545328] [R: 0.000963]\n",
      "[Epoch 11/100] [Batch 120/312] [D: -2.422415] [G: 23.508497] [R: 0.001009]\n",
      "[Epoch 11/100] [Batch 150/312] [D: -2.477407] [G: 23.499561] [R: 0.000847]\n",
      "[Epoch 11/100] [Batch 180/312] [D: -2.619994] [G: 23.424929] [R: 0.001075]\n",
      "[Epoch 11/100] [Batch 210/312] [D: -2.549133] [G: 23.454441] [R: 0.001066]\n",
      "[Epoch 11/100] [Batch 240/312] [D: -2.355675] [G: 23.640219] [R: 0.001131]\n",
      "[Epoch 11/100] [Batch 270/312] [D: -2.600127] [G: 23.493589] [R: 0.000831]\n",
      "[Epoch 11/100] [Batch 300/312] [D: -2.431762] [G: 23.812124] [R: 0.001141]\n",
      "[Epoch 12/100] [Batch 0/312] [D: -2.430218] [G: 24.031916] [R: 0.000748]\n",
      "[Epoch 12/100] [Batch 30/312] [D: -2.524985] [G: 23.919035] [R: 0.001096]\n",
      "[Epoch 12/100] [Batch 60/312] [D: -2.454365] [G: 23.965107] [R: 0.001159]\n",
      "[Epoch 12/100] [Batch 90/312] [D: -2.364678] [G: 24.153526] [R: 0.000946]\n",
      "[Epoch 12/100] [Batch 120/312] [D: -2.354885] [G: 24.103292] [R: 0.000813]\n",
      "[Epoch 12/100] [Batch 150/312] [D: -2.315937] [G: 24.396399] [R: 0.000864]\n",
      "[Epoch 12/100] [Batch 180/312] [D: -2.369402] [G: 24.056622] [R: 0.000805]\n",
      "[Epoch 12/100] [Batch 210/312] [D: -2.391931] [G: 24.196106] [R: 0.000703]\n",
      "[Epoch 12/100] [Batch 240/312] [D: -2.590200] [G: 23.811697] [R: 0.001120]\n",
      "[Epoch 12/100] [Batch 270/312] [D: -2.520552] [G: 24.097813] [R: 0.000908]\n",
      "[Epoch 12/100] [Batch 300/312] [D: -2.435456] [G: 24.158340] [R: 0.001139]\n",
      "[Epoch 13/100] [Batch 0/312] [D: -2.383970] [G: 23.974615] [R: 0.000968]\n",
      "[Epoch 13/100] [Batch 30/312] [D: -2.465812] [G: 24.077787] [R: 0.000937]\n",
      "[Epoch 13/100] [Batch 60/312] [D: -2.383911] [G: 24.016418] [R: 0.000913]\n",
      "[Epoch 13/100] [Batch 90/312] [D: -2.511586] [G: 23.526051] [R: 0.001096]\n",
      "[Epoch 13/100] [Batch 120/312] [D: -2.202808] [G: 23.966713] [R: 0.000954]\n",
      "[Epoch 13/100] [Batch 150/312] [D: -2.451040] [G: 23.639542] [R: 0.001075]\n",
      "[Epoch 13/100] [Batch 180/312] [D: -2.229732] [G: 23.703682] [R: 0.001018]\n",
      "[Epoch 13/100] [Batch 210/312] [D: -2.230191] [G: 23.598000] [R: 0.001005]\n",
      "[Epoch 13/100] [Batch 240/312] [D: -2.333036] [G: 23.615379] [R: 0.001006]\n",
      "[Epoch 13/100] [Batch 270/312] [D: -2.470971] [G: 23.573290] [R: 0.001132]\n",
      "[Epoch 13/100] [Batch 300/312] [D: -2.194576] [G: 23.788954] [R: 0.000898]\n",
      "[Epoch 14/100] [Batch 0/312] [D: -2.241251] [G: 23.614874] [R: 0.001088]\n",
      "[Epoch 14/100] [Batch 30/312] [D: -2.526781] [G: 23.420427] [R: 0.000909]\n",
      "[Epoch 14/100] [Batch 60/312] [D: -2.374254] [G: 23.376886] [R: 0.000943]\n",
      "[Epoch 14/100] [Batch 90/312] [D: -2.384165] [G: 23.539238] [R: 0.000799]\n",
      "[Epoch 14/100] [Batch 120/312] [D: -2.485690] [G: 23.170204] [R: 0.000998]\n",
      "[Epoch 14/100] [Batch 150/312] [D: -2.222041] [G: 23.588919] [R: 0.000747]\n",
      "[Epoch 14/100] [Batch 180/312] [D: -2.525512] [G: 23.230270] [R: 0.000796]\n",
      "[Epoch 14/100] [Batch 210/312] [D: -2.242397] [G: 23.466915] [R: 0.000871]\n",
      "[Epoch 14/100] [Batch 240/312] [D: -2.300083] [G: 23.505091] [R: 0.000890]\n",
      "[Epoch 14/100] [Batch 270/312] [D: -2.134254] [G: 24.050472] [R: 0.000735]\n",
      "[Epoch 14/100] [Batch 300/312] [D: -2.038787] [G: 23.866922] [R: 0.000919]\n",
      "[Epoch 15/100] [Batch 0/312] [D: -1.871998] [G: 23.974493] [R: 0.000917]\n",
      "[Epoch 15/100] [Batch 30/312] [D: -2.115479] [G: 23.823885] [R: 0.000851]\n",
      "[Epoch 15/100] [Batch 60/312] [D: -2.066988] [G: 23.791576] [R: 0.001060]\n",
      "[Epoch 15/100] [Batch 90/312] [D: -2.051356] [G: 23.734278] [R: 0.000719]\n",
      "[Epoch 15/100] [Batch 120/312] [D: -2.076832] [G: 23.808817] [R: 0.000745]\n",
      "[Epoch 15/100] [Batch 150/312] [D: -1.937616] [G: 23.794836] [R: 0.000779]\n",
      "[Epoch 15/100] [Batch 180/312] [D: -2.070690] [G: 23.629364] [R: 0.000706]\n",
      "[Epoch 15/100] [Batch 210/312] [D: -2.033896] [G: 23.667568] [R: 0.000840]\n",
      "[Epoch 15/100] [Batch 240/312] [D: -2.239882] [G: 23.577713] [R: 0.000745]\n",
      "[Epoch 15/100] [Batch 270/312] [D: -2.064242] [G: 23.849829] [R: 0.000693]\n",
      "[Epoch 15/100] [Batch 300/312] [D: -2.024486] [G: 23.769049] [R: 0.000691]\n",
      "[Epoch 16/100] [Batch 0/312] [D: -2.132211] [G: 23.702087] [R: 0.000813]\n",
      "[Epoch 16/100] [Batch 30/312] [D: -1.991747] [G: 23.640175] [R: 0.000702]\n",
      "[Epoch 16/100] [Batch 60/312] [D: -2.133389] [G: 23.510284] [R: 0.000715]\n",
      "[Epoch 16/100] [Batch 90/312] [D: -2.002172] [G: 23.701256] [R: 0.000645]\n",
      "[Epoch 16/100] [Batch 120/312] [D: -2.326604] [G: 23.316704] [R: 0.000746]\n",
      "[Epoch 16/100] [Batch 150/312] [D: -2.188755] [G: 23.552744] [R: 0.000679]\n",
      "[Epoch 16/100] [Batch 180/312] [D: -2.269927] [G: 23.297485] [R: 0.000663]\n",
      "[Epoch 16/100] [Batch 210/312] [D: -2.392105] [G: 23.121948] [R: 0.000676]\n",
      "[Epoch 16/100] [Batch 240/312] [D: -2.402410] [G: 23.284281] [R: 0.000655]\n",
      "[Epoch 16/100] [Batch 270/312] [D: -2.200457] [G: 23.293716] [R: 0.000680]\n",
      "[Epoch 16/100] [Batch 300/312] [D: -2.189331] [G: 23.269234] [R: 0.000672]\n",
      "[Epoch 17/100] [Batch 0/312] [D: -2.177824] [G: 23.243776] [R: 0.000667]\n",
      "[Epoch 17/100] [Batch 30/312] [D: -1.934185] [G: 23.416758] [R: 0.000769]\n",
      "[Epoch 17/100] [Batch 60/312] [D: -2.135913] [G: 23.509655] [R: 0.000673]\n",
      "[Epoch 17/100] [Batch 90/312] [D: -2.197348] [G: 23.057777] [R: 0.000791]\n",
      "[Epoch 17/100] [Batch 120/312] [D: -2.037949] [G: 23.595566] [R: 0.000665]\n",
      "[Epoch 17/100] [Batch 150/312] [D: -1.977825] [G: 23.554794] [R: 0.000711]\n",
      "[Epoch 17/100] [Batch 180/312] [D: -1.978017] [G: 23.576118] [R: 0.000654]\n",
      "[Epoch 17/100] [Batch 210/312] [D: -2.178935] [G: 23.466143] [R: 0.000723]\n",
      "[Epoch 17/100] [Batch 240/312] [D: -2.071859] [G: 23.764103] [R: 0.000787]\n",
      "[Epoch 17/100] [Batch 270/312] [D: -2.110343] [G: 23.636719] [R: 0.000663]\n",
      "[Epoch 17/100] [Batch 300/312] [D: -2.189751] [G: 23.796209] [R: 0.000760]\n",
      "[Epoch 18/100] [Batch 0/312] [D: -2.257478] [G: 23.877777] [R: 0.000680]\n",
      "[Epoch 18/100] [Batch 30/312] [D: -2.104526] [G: 23.730356] [R: 0.000707]\n",
      "[Epoch 18/100] [Batch 60/312] [D: -2.329371] [G: 23.536219] [R: 0.000762]\n",
      "[Epoch 18/100] [Batch 90/312] [D: -2.043421] [G: 23.780172] [R: 0.000854]\n",
      "[Epoch 18/100] [Batch 120/312] [D: -2.044390] [G: 23.972761] [R: 0.000950]\n",
      "[Epoch 18/100] [Batch 150/312] [D: -2.202981] [G: 23.612627] [R: 0.000655]\n",
      "[Epoch 18/100] [Batch 180/312] [D: -2.167308] [G: 23.851765] [R: 0.000625]\n",
      "[Epoch 18/100] [Batch 210/312] [D: -2.285121] [G: 23.772865] [R: 0.000636]\n",
      "[Epoch 18/100] [Batch 240/312] [D: -2.261986] [G: 23.649088] [R: 0.000691]\n",
      "[Epoch 18/100] [Batch 270/312] [D: -2.471228] [G: 23.123100] [R: 0.000637]\n",
      "[Epoch 18/100] [Batch 300/312] [D: -2.414352] [G: 23.483477] [R: 0.000586]\n",
      "[Epoch 19/100] [Batch 0/312] [D: -2.199665] [G: 23.790937] [R: 0.000610]\n",
      "[Epoch 19/100] [Batch 30/312] [D: -2.345359] [G: 23.599535] [R: 0.000579]\n",
      "[Epoch 19/100] [Batch 60/312] [D: -2.238838] [G: 23.829712] [R: 0.000569]\n",
      "[Epoch 19/100] [Batch 90/312] [D: -2.043872] [G: 23.923323] [R: 0.000549]\n",
      "[Epoch 19/100] [Batch 120/312] [D: -2.241031] [G: 23.566202] [R: 0.000537]\n",
      "[Epoch 19/100] [Batch 150/312] [D: -2.152669] [G: 23.885197] [R: 0.000562]\n",
      "[Epoch 19/100] [Batch 180/312] [D: -2.008463] [G: 23.960340] [R: 0.000692]\n",
      "[Epoch 19/100] [Batch 210/312] [D: -2.163837] [G: 23.850018] [R: 0.000645]\n",
      "[Epoch 19/100] [Batch 240/312] [D: -2.009385] [G: 23.913403] [R: 0.000637]\n",
      "[Epoch 19/100] [Batch 270/312] [D: -2.054821] [G: 23.859283] [R: 0.000583]\n",
      "[Epoch 19/100] [Batch 300/312] [D: -2.352369] [G: 23.499662] [R: 0.000620]\n",
      "[Epoch 20/100] [Batch 0/312] [D: -1.846181] [G: 23.869270] [R: 0.000734]\n",
      "[Epoch 20/100] [Batch 30/312] [D: -2.149438] [G: 23.469122] [R: 0.000640]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 20/100] [Batch 60/312] [D: -2.088685] [G: 23.359585] [R: 0.000602]\n",
      "[Epoch 20/100] [Batch 90/312] [D: -1.921570] [G: 23.695976] [R: 0.000663]\n",
      "[Epoch 20/100] [Batch 120/312] [D: -2.097611] [G: 23.480284] [R: 0.000649]\n",
      "[Epoch 20/100] [Batch 150/312] [D: -1.897034] [G: 23.700644] [R: 0.000622]\n",
      "[Epoch 20/100] [Batch 180/312] [D: -1.801684] [G: 23.479607] [R: 0.000567]\n",
      "[Epoch 20/100] [Batch 210/312] [D: -1.973383] [G: 23.289009] [R: 0.000640]\n",
      "[Epoch 20/100] [Batch 240/312] [D: -1.962484] [G: 23.388706] [R: 0.000591]\n",
      "[Epoch 20/100] [Batch 270/312] [D: -1.888917] [G: 23.522612] [R: 0.000535]\n",
      "[Epoch 20/100] [Batch 300/312] [D: -1.988287] [G: 23.309553] [R: 0.000550]\n",
      "[Epoch 21/100] [Batch 0/312] [D: -1.985304] [G: 23.358320] [R: 0.000641]\n",
      "[Epoch 21/100] [Batch 30/312] [D: -1.878640] [G: 23.376392] [R: 0.000569]\n",
      "[Epoch 21/100] [Batch 60/312] [D: -2.174817] [G: 23.062967] [R: 0.000547]\n",
      "[Epoch 21/100] [Batch 90/312] [D: -2.047591] [G: 23.224112] [R: 0.000534]\n",
      "[Epoch 21/100] [Batch 120/312] [D: -1.771631] [G: 23.131517] [R: 0.000566]\n",
      "[Epoch 21/100] [Batch 150/312] [D: -1.966835] [G: 22.768250] [R: 0.000522]\n",
      "[Epoch 21/100] [Batch 180/312] [D: -1.961827] [G: 22.858921] [R: 0.000494]\n",
      "[Epoch 21/100] [Batch 210/312] [D: -2.322247] [G: 22.987347] [R: 0.000534]\n",
      "[Epoch 21/100] [Batch 240/312] [D: -1.906662] [G: 22.943659] [R: 0.000576]\n",
      "[Epoch 21/100] [Batch 270/312] [D: -2.124454] [G: 22.856056] [R: 0.000541]\n",
      "[Epoch 21/100] [Batch 300/312] [D: -1.984889] [G: 23.016621] [R: 0.000546]\n",
      "[Epoch 22/100] [Batch 0/312] [D: -1.848933] [G: 23.002384] [R: 0.000581]\n",
      "[Epoch 22/100] [Batch 30/312] [D: -1.974917] [G: 23.004124] [R: 0.000589]\n",
      "[Epoch 22/100] [Batch 60/312] [D: -1.831850] [G: 23.107651] [R: 0.000584]\n",
      "[Epoch 22/100] [Batch 90/312] [D: -1.885183] [G: 22.749493] [R: 0.000575]\n",
      "[Epoch 22/100] [Batch 120/312] [D: -1.794158] [G: 23.153904] [R: 0.000527]\n",
      "[Epoch 22/100] [Batch 150/312] [D: -2.096851] [G: 23.031830] [R: 0.000494]\n",
      "[Epoch 22/100] [Batch 180/312] [D: -1.913638] [G: 23.124226] [R: 0.000638]\n",
      "[Epoch 22/100] [Batch 210/312] [D: -1.817160] [G: 23.189144] [R: 0.000522]\n",
      "[Epoch 22/100] [Batch 240/312] [D: -1.901218] [G: 23.321032] [R: 0.000516]\n",
      "[Epoch 22/100] [Batch 270/312] [D: -1.950371] [G: 23.383902] [R: 0.000591]\n",
      "[Epoch 22/100] [Batch 300/312] [D: -1.651027] [G: 23.496378] [R: 0.000542]\n",
      "[Epoch 23/100] [Batch 0/312] [D: -1.885356] [G: 23.567205] [R: 0.000538]\n",
      "[Epoch 23/100] [Batch 30/312] [D: -1.715817] [G: 23.701199] [R: 0.000550]\n",
      "[Epoch 23/100] [Batch 60/312] [D: -2.113702] [G: 23.822681] [R: 0.000700]\n",
      "[Epoch 23/100] [Batch 90/312] [D: -1.939748] [G: 23.396072] [R: 0.000602]\n",
      "[Epoch 23/100] [Batch 120/312] [D: -1.791052] [G: 23.644779] [R: 0.000605]\n",
      "[Epoch 23/100] [Batch 150/312] [D: -2.205628] [G: 23.100840] [R: 0.000508]\n",
      "[Epoch 23/100] [Batch 180/312] [D: -1.793186] [G: 23.362347] [R: 0.000608]\n",
      "[Epoch 23/100] [Batch 210/312] [D: -1.982888] [G: 23.282919] [R: 0.000567]\n",
      "[Epoch 23/100] [Batch 240/312] [D: -1.960725] [G: 23.476046] [R: 0.000650]\n",
      "[Epoch 23/100] [Batch 270/312] [D: -1.975114] [G: 23.427664] [R: 0.000527]\n",
      "[Epoch 23/100] [Batch 300/312] [D: -2.024015] [G: 23.263094] [R: 0.000562]\n",
      "[Epoch 24/100] [Batch 0/312] [D: -2.094258] [G: 23.434597] [R: 0.000518]\n",
      "[Epoch 24/100] [Batch 30/312] [D: -1.802781] [G: 23.569149] [R: 0.000536]\n",
      "[Epoch 24/100] [Batch 60/312] [D: -1.972109] [G: 23.360607] [R: 0.000561]\n",
      "[Epoch 24/100] [Batch 90/312] [D: -2.047915] [G: 23.492809] [R: 0.000571]\n",
      "[Epoch 24/100] [Batch 120/312] [D: -1.748232] [G: 23.637278] [R: 0.000567]\n",
      "[Epoch 24/100] [Batch 150/312] [D: -2.002430] [G: 23.354769] [R: 0.000605]\n",
      "[Epoch 24/100] [Batch 180/312] [D: -1.943580] [G: 23.466713] [R: 0.000620]\n",
      "[Epoch 24/100] [Batch 210/312] [D: -2.113116] [G: 23.154633] [R: 0.000551]\n",
      "[Epoch 24/100] [Batch 240/312] [D: -1.860707] [G: 23.400307] [R: 0.000714]\n",
      "[Epoch 24/100] [Batch 270/312] [D: -2.022955] [G: 23.103703] [R: 0.000611]\n",
      "[Epoch 24/100] [Batch 300/312] [D: -1.890743] [G: 23.357227] [R: 0.000575]\n",
      "[Epoch 25/100] [Batch 0/312] [D: -1.791323] [G: 23.319946] [R: 0.000675]\n",
      "[Epoch 25/100] [Batch 30/312] [D: -1.715532] [G: 23.168587] [R: 0.000548]\n",
      "[Epoch 25/100] [Batch 60/312] [D: -1.899844] [G: 23.207167] [R: 0.000604]\n",
      "[Epoch 25/100] [Batch 90/312] [D: -2.021683] [G: 23.260899] [R: 0.000597]\n",
      "[Epoch 25/100] [Batch 120/312] [D: -1.831035] [G: 23.170429] [R: 0.000675]\n",
      "[Epoch 25/100] [Batch 150/312] [D: -1.861736] [G: 23.447872] [R: 0.000588]\n",
      "[Epoch 25/100] [Batch 180/312] [D: -1.904040] [G: 23.292675] [R: 0.000569]\n",
      "[Epoch 25/100] [Batch 210/312] [D: -1.922268] [G: 23.371262] [R: 0.000545]\n",
      "[Epoch 25/100] [Batch 240/312] [D: -1.968502] [G: 23.337957] [R: 0.000456]\n",
      "[Epoch 25/100] [Batch 270/312] [D: -1.728914] [G: 23.422201] [R: 0.000621]\n",
      "[Epoch 25/100] [Batch 300/312] [D: -1.821996] [G: 23.027153] [R: 0.000635]\n",
      "[Epoch 26/100] [Batch 0/312] [D: -1.917473] [G: 22.799519] [R: 0.000569]\n",
      "[Epoch 26/100] [Batch 30/312] [D: -1.772050] [G: 23.235081] [R: 0.000496]\n",
      "[Epoch 26/100] [Batch 60/312] [D: -1.846223] [G: 23.260843] [R: 0.000489]\n",
      "[Epoch 26/100] [Batch 90/312] [D: -2.070109] [G: 22.841360] [R: 0.000459]\n",
      "[Epoch 26/100] [Batch 120/312] [D: -1.808118] [G: 22.857067] [R: 0.000511]\n",
      "[Epoch 26/100] [Batch 150/312] [D: -1.826284] [G: 23.036615] [R: 0.000540]\n",
      "[Epoch 26/100] [Batch 180/312] [D: -1.644455] [G: 22.918634] [R: 0.000629]\n",
      "[Epoch 26/100] [Batch 210/312] [D: -1.797253] [G: 22.601957] [R: 0.000597]\n",
      "[Epoch 26/100] [Batch 240/312] [D: -1.893910] [G: 22.567057] [R: 0.000606]\n",
      "[Epoch 26/100] [Batch 270/312] [D: -1.645039] [G: 22.514997] [R: 0.000572]\n",
      "[Epoch 26/100] [Batch 300/312] [D: -1.581777] [G: 23.114059] [R: 0.000536]\n",
      "[Epoch 27/100] [Batch 0/312] [D: -1.677394] [G: 23.004995] [R: 0.000613]\n",
      "[Epoch 27/100] [Batch 30/312] [D: -1.657874] [G: 22.815025] [R: 0.000597]\n",
      "[Epoch 27/100] [Batch 60/312] [D: -1.613323] [G: 22.897938] [R: 0.000643]\n",
      "[Epoch 27/100] [Batch 90/312] [D: -1.722271] [G: 22.603008] [R: 0.000728]\n",
      "[Epoch 27/100] [Batch 120/312] [D: -1.639681] [G: 22.513552] [R: 0.000594]\n",
      "[Epoch 27/100] [Batch 150/312] [D: -1.883200] [G: 22.426901] [R: 0.000675]\n",
      "[Epoch 27/100] [Batch 180/312] [D: -1.667889] [G: 22.152542] [R: 0.000608]\n",
      "[Epoch 27/100] [Batch 210/312] [D: -1.787484] [G: 21.998964] [R: 0.000628]\n",
      "[Epoch 27/100] [Batch 240/312] [D: -2.039042] [G: 21.719173] [R: 0.000645]\n",
      "[Epoch 27/100] [Batch 270/312] [D: -1.925607] [G: 22.183033] [R: 0.000644]\n",
      "[Epoch 27/100] [Batch 300/312] [D: -1.679167] [G: 21.781118] [R: 0.000569]\n",
      "[Epoch 28/100] [Batch 0/312] [D: -1.683140] [G: 21.831541] [R: 0.000566]\n",
      "[Epoch 28/100] [Batch 30/312] [D: -1.490795] [G: 22.092491] [R: 0.000559]\n",
      "[Epoch 28/100] [Batch 60/312] [D: -1.466102] [G: 21.976990] [R: 0.000557]\n",
      "[Epoch 28/100] [Batch 90/312] [D: -1.592850] [G: 21.573812] [R: 0.000692]\n",
      "[Epoch 28/100] [Batch 120/312] [D: -1.575140] [G: 21.635899] [R: 0.000545]\n",
      "[Epoch 28/100] [Batch 150/312] [D: -1.374960] [G: 21.805319] [R: 0.000616]\n",
      "[Epoch 28/100] [Batch 180/312] [D: -1.430017] [G: 21.578657] [R: 0.000620]\n",
      "[Epoch 28/100] [Batch 210/312] [D: -1.519106] [G: 21.812372] [R: 0.000579]\n",
      "[Epoch 28/100] [Batch 240/312] [D: -1.257432] [G: 21.754789] [R: 0.000639]\n",
      "[Epoch 28/100] [Batch 270/312] [D: -1.623481] [G: 21.474506] [R: 0.000624]\n",
      "[Epoch 28/100] [Batch 300/312] [D: -1.550174] [G: 21.357513] [R: 0.000715]\n",
      "[Epoch 29/100] [Batch 0/312] [D: -1.680081] [G: 21.049408] [R: 0.000688]\n",
      "[Epoch 29/100] [Batch 30/312] [D: -1.694116] [G: 21.316187] [R: 0.000726]\n",
      "[Epoch 29/100] [Batch 60/312] [D: -1.932912] [G: 21.090319] [R: 0.000622]\n",
      "[Epoch 29/100] [Batch 90/312] [D: -1.582155] [G: 21.314611] [R: 0.000636]\n",
      "[Epoch 29/100] [Batch 120/312] [D: -1.579534] [G: 20.771614] [R: 0.000616]\n",
      "[Epoch 29/100] [Batch 150/312] [D: -1.716620] [G: 20.833506] [R: 0.000732]\n",
      "[Epoch 29/100] [Batch 180/312] [D: -1.712388] [G: 20.558367] [R: 0.000714]\n",
      "[Epoch 29/100] [Batch 210/312] [D: -1.748683] [G: 20.642859] [R: 0.000669]\n",
      "[Epoch 29/100] [Batch 240/312] [D: -1.683570] [G: 20.508799] [R: 0.000671]\n",
      "[Epoch 29/100] [Batch 270/312] [D: -1.924928] [G: 20.420866] [R: 0.000688]\n",
      "[Epoch 29/100] [Batch 300/312] [D: -1.883510] [G: 20.646955] [R: 0.000601]\n",
      "[Epoch 30/100] [Batch 0/312] [D: -1.880936] [G: 20.436369] [R: 0.000573]\n",
      "[Epoch 30/100] [Batch 30/312] [D: -1.626055] [G: 20.626434] [R: 0.000602]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 30/100] [Batch 60/312] [D: -1.373586] [G: 20.984694] [R: 0.000638]\n",
      "[Epoch 30/100] [Batch 90/312] [D: -1.675427] [G: 20.980112] [R: 0.000549]\n",
      "[Epoch 30/100] [Batch 120/312] [D: -1.639979] [G: 21.149597] [R: 0.000590]\n",
      "[Epoch 30/100] [Batch 150/312] [D: -1.563017] [G: 21.466221] [R: 0.000611]\n",
      "[Epoch 30/100] [Batch 180/312] [D: -1.718725] [G: 21.314804] [R: 0.000565]\n",
      "[Epoch 30/100] [Batch 210/312] [D: -1.348567] [G: 21.242332] [R: 0.000619]\n",
      "[Epoch 30/100] [Batch 240/312] [D: -1.530615] [G: 21.088486] [R: 0.000634]\n",
      "[Epoch 30/100] [Batch 270/312] [D: -1.544370] [G: 21.059452] [R: 0.000589]\n",
      "[Epoch 30/100] [Batch 300/312] [D: -1.447633] [G: 21.146099] [R: 0.000618]\n",
      "[Epoch 31/100] [Batch 0/312] [D: -1.521239] [G: 21.080671] [R: 0.000607]\n",
      "[Epoch 31/100] [Batch 30/312] [D: -1.275947] [G: 20.960796] [R: 0.000584]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-e360100d39e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0moptimizer_G\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mx_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mreal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mfake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/splinter/ddm/taggenv/lib64/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/splinter/ddm/taggingProject/taggingRepo/tagging/src/networks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, train_encoder, train_decoder)\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrain_encoder\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m             \u001b[0mlatent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrain_decoder\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/splinter/ddm/taggenv/lib64/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/splinter/ddm/taggingProject/taggingRepo/tagging/src/networks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, optional, optional2)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;31m#for layer in layers:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;31m#    x = layer(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/splinter/ddm/taggenv/lib64/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/splinter/ddm/taggenv/lib64/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/splinter/ddm/taggenv/lib64/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/splinter/ddm/taggenv/lib64/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/splinter/ddm/taggenv/lib64/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batches_done = 0\n",
    "for epoch in range(10000):\n",
    "    for i, (x,u,v,idx) in enumerate(loader):\n",
    "        optimizer_G.zero_grad()\n",
    "        x_pred,z = autoencoder(x)\n",
    "        real = z\n",
    "        fake = torch.randn(z.shape)\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # Real images\n",
    "        real_validity = discriminator(real)\n",
    "        # Fake images\n",
    "        fake_validity = discriminator(fake)\n",
    "        # Gradient penalty\n",
    "        gradient_penalty = compute_gradient_penalty(discriminator, real.data, fake.data)\n",
    "        # Adversarial loss\n",
    "        d_loss = -torch.mean(real_validity) + torch.mean(fake_validity) + lambda_gp * gradient_penalty\n",
    "\n",
    "        d_loss.backward(retain_graph=True)\n",
    "        optimizer_D.step()\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Train the generator every n_critic steps\n",
    "        if i % n_critic == 0:\n",
    "\n",
    "            # -----------------\n",
    "            #  Train Generator\n",
    "            # -----------------\n",
    "\n",
    "            # Loss measures generator's ability to fool the discriminator\n",
    "            # Train on fake images\n",
    "            fake_validity = discriminator(fake)\n",
    "            real_validity = discriminator(real)\n",
    "\n",
    "            err_pred = loss(x_pred,x)\n",
    "\n",
    "            g_loss = err_pred-lambda_fact*10*(torch.mean(fake_validity)-torch.mean(real_validity))\n",
    "\n",
    "\n",
    "            g_loss.backward()\n",
    "            optimizer_G.step()\n",
    "            if i%30*n_critic ==0:\n",
    "                print(\n",
    "                    \"[Epoch %d/%d] [Batch %d/%d] [D: %f] [G: %f] [R: %f]\"\n",
    "                    % (epoch, 100, i, len(loader), d_loss.item(), torch.mean(fake_validity).item(),err_pred.item())\n",
    "                )\n",
    "\n",
    "\n",
    "                batches_done += n_critic\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.12690074, 0.2220763 , 0.15862593, 0.28552667, 0.34897704,\n",
       "        0.41242741, 0.28552667, 0.09517556, 0.06345039, 0.03172518]),\n",
       " array([-2.3181472 , -1.8256363 , -1.3331254 , -0.84061444, -0.34810352,\n",
       "         0.14440739,  0.6369183 ,  1.1294292 ,  1.6219401 ,  2.114451  ,\n",
       "         2.606962  ], dtype=float32),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(real[:,5].detach(),density=True)\n",
    "plt.hist(fake[:,5].detach(),alpha=0.5,density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.02911856, 0.02911854, 0.05823711, 0.2329484 , 0.43677825,\n",
       "        0.2329484 , 0.4076597 , 0.26206698, 0.14559275, 0.02911855]),\n",
       " array([-3.0539224 , -2.517323  , -1.9807234 , -1.444124  , -0.90752447,\n",
       "        -0.37092495,  0.16567454,  0.702274  ,  1.2388735 ,  1.775473  ,\n",
       "         2.3120725 ], dtype=float32),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(real[:,6].detach(),density=True)\n",
    "plt.hist(fake[:,3].detach(),alpha=0.5,density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.01253941, 0.0532925 , 0.16771465, 0.27586706, 0.34640125,\n",
       "        0.38558691, 0.23981625, 0.09091074, 0.02664625, 0.00626971]),\n",
       " array([-2.9861386, -2.363103 , -1.7400674, -1.1170318, -0.4939962,\n",
       "         0.1290394,  0.752075 ,  1.3751106,  1.9981462,  2.6211817,\n",
       "         3.2442174], dtype=float32),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(real[:].detach().flatten(),density=True)\n",
    "plt.hist(fake[:].detach().flatten(),alpha=0.5,density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taggenv",
   "language": "python",
   "name": "taggenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
