{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weakly-supervised learning\n",
    "\n",
    "The idea of this notebook is to train a neural network at reconstructing spectra while also using weakly supervised learning to ensure that a fraction of the representation is as well preserved as possible for stars from the same cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['TEFF', 'LOGG', 'LOG10VDOP', 'METALS', 'C', 'N', 'O Mg Si S Ca Ti'], ['C', 'N', 'O', 'Na', 'Mg', 'Al', 'Si', 'S', 'K', 'Ca', 'Ti', 'V', 'Mn', 'Fe', 'Ni'], ['[C/M]', '[N/M]', '[O/M]', '[Na/H]', '[Mg/M]', '[Al/H]', '[Si/M]', '[S/M]', '[K/H]', '[Ca/M]', '[Ti/M]', '[V/H]', '[Mn/H]', '[Fe/H]', '[Ni/H]'], [0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1])]\n"
     ]
    }
   ],
   "source": [
    "import apogee.tools.read as apread\n",
    "import matplotlib.pyplot as plt \n",
    "import apogee.tools.path as apogee_path\n",
    "from apogee.tools import bitmask\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch.nn as nn\n",
    "\n",
    "from apoNN.src.datasets import ApogeeDataset,AspcapDataset\n",
    "from apoNN.src.utils import get_mask_elem,dump,load,generate_loss_with_masking\n",
    "\n",
    "import apoNN.src.vectors as vector\n",
    "\n",
    "\n",
    "from tagging.src.networks import ConditioningAutoencoder,Embedding_Decoder,Feedforward,ParallelDecoder,Autoencoder,AutoencoderwLinear\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "apogee_path.change_dr(16)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "\n",
    "We dump here all of our hyperparmeters for dealing with latter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"aspcap_training_clean\"\n",
    "recenter=True\n",
    "n_bins = 8575\n",
    "n_z = 7\n",
    "n_shared = 5\n",
    "activation = nn.LeakyReLU()\n",
    "lr = 0.00005\n",
    "n_batch = 64\n",
    "encoder_architecture = [n_bins,512,256,128,n_z]\n",
    "decoder_architecture = [n_z,128,256,512,n_bins]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the data\n",
    "\n",
    "\n",
    "We need two datasets. One containing the full dataset and another containing the occam dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = AspcapDataset(filename=dataset_name,recenter=recenter)\n",
    "dataset_occam = AspcapDataset(filename=\"aspcap_occam\",recenter=True,tensor_type=torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = torch.utils.data.DataLoader(dataset = dataset,\n",
    "                                     batch_size = n_batch,\n",
    "                                     shuffle= True,\n",
    "                                     drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "occam = load(\"occam\")\n",
    "occam_cluster_idxs = occam[\"cluster_idxs\"]\n",
    "registry = vector.OccamLatentVector.make_registry(occam_cluster_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Feedforward(encoder_architecture ,activation=activation).to(device)\n",
    "decoder = Feedforward(decoder_architecture ,activation=activation).to(device)\n",
    "#autoencoder = Autoencoder(encoder,decoder,n_bins=n_bins,intermediate_activation=activation).to(device)\n",
    "#optimizer_autoencoder = torch.optim.Adam(autoencoder.parameters(), lr=lr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_bottleneck = Feedforward([n_z,n_z,n_z,n_z],activation=None).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoencoderwLinear(\n",
       "  (encoder): Feedforward(\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=8575, out_features=512, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=128, out_features=7, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Feedforward(\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=7, out_features=128, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=128, out_features=256, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=256, out_features=512, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Linear(in_features=512, out_features=8575, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (linear): Feedforward(\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=7, out_features=7, bias=True)\n",
       "      (1): Linear(in_features=7, out_features=7, bias=True)\n",
       "      (2): Linear(in_features=7, out_features=7, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (intermediate_activation): LeakyReLU(negative_slope=0.01)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AutoencoderwLinear(encoder,decoder,linear_bottleneck,n_bins=n_bins,intermediate_activation=activation).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_bottleneck(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.L1Loss()\n",
    "masked_loss = generate_loss_with_masking(loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,occam_idxs = random.choice(list(registry.items()))\n",
    "occam_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_occam[occam_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_std_sample(z_occam,z_full,eps=0.0000001):\n",
    "    #occam_std = torch.std(z_occam,dim=0)\n",
    "    #full_std = torch.std(z_full,dim=0)\n",
    "    #return torch.mean(occam_std/(full_std+eps))\n",
    "    return torch.mean(torch.abs(z_occam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_loss= []\n",
    "for i in range(30000):\n",
    "    for j,(x,x_raw,x_err,idx) in enumerate(loader):\n",
    "        optimizer_autoencoder.zero_grad()\n",
    "        \n",
    "        #occam-sample\n",
    "        _,occam_idxs = random.choice(list(registry.items()))\n",
    "        x_occam,x_occam_raw,x_occam_err,occam_idx = dataset_occam[occam_idxs]\n",
    "        _,z_occam = autoencoder(x.to(device))\n",
    "        z_occam_shared = z_occam[:,:n_shared]\n",
    "\n",
    "        #regular sample\n",
    "        x_pred,z = autoencoder(x.to(device))\n",
    "        z_shared = z[:,:n_shared]\n",
    "\n",
    "        mask_spec = x_err<dataset.err_threshold\n",
    "        err_pred = masked_loss(x_pred,x.to(device),mask_spec)\n",
    "        err_std = loss_std_sample(z_occam_shared,z_shared)\n",
    "        \n",
    "        err_tot = err_std+err_pred+err_std\n",
    "        err_tot.backward()\n",
    "        optimizer_autoencoder.step()\n",
    "        print(f\"err:{err_tot},err_pred:{err_pred},err_std:{err_std}\")\n",
    "    training_loss.append(err_pred.item())\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(autoencoder.encoder.fc[2].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taggenv",
   "language": "python",
   "name": "taggenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
