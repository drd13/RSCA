{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "\n",
    "Code for reproducing experiments shown in the paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import apoNN.src.data as apoData\n",
    "import apoNN.src.utils as apoUtils\n",
    "import apoNN.src.vectors as vectors\n",
    "import apoNN.src.fitters as fitters\n",
    "import apoNN.src.evaluators as evaluators\n",
    "import apoNN.src.occam as occam_utils\n",
    "\n",
    "import sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "import random\n",
    "from ppca import PPCA\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we use the [```apogee```](https://github.com/jobovy/apogee) module for interacting with APOGEE data and make use of dr16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import apogee.tools.path as apogee_path\n",
    "apogee_path.change_dr(16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "\n",
    "For speed we can run the results using only a subset of spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_start = 0\n",
    "n_stars = 50000 #100000\n",
    "d = 100 #number of dimensions to use for compression\n",
    "tol = 0.01 # tolerance to use for PPCA. Larger means faster but less accurate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We load the AllStar file and make appropriate datacuts. This yields ```alllStar_occamlike``` - a large dataset containing all those spectra matching the dataset cuts in the data release 16 - and ```allStar_occam``` containing those stars within ```alllStar_occamlike``` cross-matched with the occam open cluster dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allStar = apoUtils.load(\"shuffled_allStar\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_temp_cut = allStar[\"Teff\"]<5000\n",
    "lower_temp_cut = allStar[\"Teff\"]>4000\n",
    "lower_g_cut = allStar[\"logg\"]>1.5\n",
    "upper_g_cut = allStar[\"logg\"]<3.\n",
    "occamlike_cut = lower_g_cut & upper_g_cut & lower_temp_cut & upper_temp_cut\n",
    "allStar_occamlike =  allStar[np.where(occamlike_cut)]\n",
    "\n",
    "\n",
    "occam = occam_utils.Occam()\n",
    "occam_kept = occam.cg_prob>0.8\n",
    "allStar_occam,cluster_idxs = occam_utils.prepare_occam_allStar(occam_kept,allStar_occamlike)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a few apogee id return na in the astronn catalogue. We remove these frmo our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_apogee_id = ['2M02123870+4942289', '2M18051909-3214413', '2M06134865+5518282']\n",
    "good_ids = [apogee_id not in bad_apogee_id for apogee_id in allStar_occamlike[\"Apogee_id\"]]\n",
    "allStar_occamlike = allStar_occamlike[good_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert allStar files into the continuum-normalized spectra using ```apoData.Dataset```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_occamlike = apoData.Dataset(allStar_occamlike[n_start:n_start+n_stars])\n",
    "data_occam = apoData.Dataset(allStar_occam)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```cluster_idxs``` contains the clusters to which entries in ```data_occam``` belong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(cluster_idxs.shape[0] == data_occam.masked_spectra.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compression\n",
    "\n",
    "```apoData.Dataset``` returns spectra for which bins with errors above a threshold are masked. We run a PCA that naturally handles missing values using the [ppca module](https://github.com/allentran/pca-magic). This is wrapped in a function ```fitters.compress_masked_spectra``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_interstellar, interstellar_locs = apoUtils.get_interstellar_bands()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z,z_occam,ppca = fitters.compress_masked_spectra(data_occamlike.masked_spectra[:,mask_interstellar],data_occam.masked_spectra[:,mask_interstellar],d,tol=tol)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#z,z_occam,ppca = fitters.compress_masked_spectra(data_occamlike.masked_spectra,data_occam.masked_spectra,d,tol=tol)\n",
    "z,z_occam,ppca = fitters.compress_masked_spectra(data_occamlike.masked_spectra,data_occam.masked_spectra,d,tol=tol)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated in the paper, our evaluation method requires using our approach on unseen clusters through a cross-validation scheme. This is handled through the ```evaluators.StandardEvaluator``` class which takes ```vectors.Vector``` as inputs. It is run as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_occam = vectors.OccamVector(val = z_occam,cluster_names=cluster_idxs).remove_orphans()\n",
    "Z = vectors.Vector(val = z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vectors come with lots of handy functions. For example we can see which stars belong to which clusters using ```vectors.OccamVector.registry``` or even remove a cluster using ```vectors.OccamVector.without()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z.val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Z_occam.registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_occam.without(\"NGC 6791\").registry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline\n",
    "\n",
    "As our baseline we use the AstroNN abundances. We use the ```vectors.AstroNNVector``` to create an AstroNN vector from an allStar file. Parameters included in the vector are passed through a ```considered_parameters``` input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "considered_parameters = [\"Fe_H\",\"C_FE\",\"N_FE\",\"O_FE\",\"Na_FE\",\"Mg_FE\",\"Al_FE\",\"Si_FE\",\"S_FE\",\"K_FE\",\"CA_FE\",\"Ni_FE\",\"Cr_FE\",\"Co_FE\"] \n",
    "#considered_parameters = [\"AK_targ\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#element_string = \"[Fe/H], \"\n",
    "#for param in considered_parameters[1:]:\n",
    "#    s1,s2 = param.split(\"_\")\n",
    "#    element_string+=f\"[{s1}/{s2}], \"\n",
    "#print(element_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = vectors.AstroNNVector(allStar_occamlike[n_start:n_start+n_stars],considered_parameters).remove_nan_cols()\n",
    "#because one of the entries in the AstroNN catalogue contains nan. we remove it with Y.remove_nan_cols()\n",
    "Y_occam = vectors.AstroNNVector(allStar_occam,considered_parameters)\n",
    "Y_occam = vectors.OccamVector(cluster_names=cluster_idxs, val = Y_occam.val).remove_orphans()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yb = vectors.AstroNNVector(allStar_occamlike[n_start:n_start+n_stars],considered_parameters+[\"Teff\",\"logg\"]).remove_nan_cols()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yb = vectors.AstroNNVector(allStar_occamlike[n_start:n_start+n_stars],considered_parameters+[\"Teff\",\"logg\"]).remove_nan_cols()\n",
    "#because one of the entries in the AstroNN catalogue contains nan. we remove it with Y.remove_nan_cols()\n",
    "Yb_occam = vectors.AstroNNVector(allStar_occam,considered_parameters+[\"Teff\",\"logg\"])\n",
    "\n",
    "Yb_occam = vectors.OccamVector(cluster_names=cluster_idxs, val = Yb_occam.val).remove_orphans()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inspect.getsource(vectors.AstroNNVector))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting performance against number of components\n",
    "\n",
    "For our experiment we want to determine how performance compares with the number of dimensions preserved in the PCA step. We also want to compare against the performance obtained using abundances.\n",
    "\n",
    "There are two ingredients required for assessing performance\n",
    "\n",
    "- a ```fitters.Fitter``` object that takes vectors (spectra, stellar parameters) and scales them to encode chemical similarity. \n",
    "\n",
    "- a ```evaluators.Evaluator``` object that takes a fitter, and unsupervised dataset, an occam dataset and calculates the doppelganger rates of a representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inspect.getsource(evaluators.BaseEvaluator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(inspect.getsource(fitters.StandardFitter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_fitter(z,z_occam):\n",
    "    \"\"\"This is a simple fitter that just scales the dimensions of the inputed representation. Which is used as a baseline\"\"\"\n",
    "    return fitters.SimpleFitter(z,z_occam,use_relative_scaling=True,is_pooled=True,is_robust=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_fitter(z,z_occam):\n",
    "    \"\"\"This fitter performs a change-of-basis to a more appropriate basis for scaling\"\"\"\n",
    "    return fitters.StandardFitter(z,z_occam,use_relative_scaling=True,is_pooled=True,is_robust=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_Y = evaluators.StandardEvaluator(Y,Y_occam,leave_out=True,fitter_class=standard_fitter)\n",
    "evaluator_Y.weighted_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_Y_overfit = evaluators.StandardEvaluator(Y,Y_occam,leave_out=False,fitter_class=standard_fitter)\n",
    "evaluator_Y_overfit.weighted_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_components = [5,15,25,35,45,55,65,75,85,95]\n",
    "evaluators_X = [evaluators.StandardEvaluator(Z[:,:n_component],Z_occam[:,:n_component],leave_out=True,fitter_class=standard_fitter) for n_component in n_components]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i.weighted_average for i in evaluators_X]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can pass ```leave_out=False``` in which case the (overfitted) results without cross-validation are shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluators_X_overfit = [evaluators.StandardEvaluator(Z[:,:n_component],Z_occam[:,:n_component],leave_out=False,fitter_class=standard_fitter) for n_component in n_components]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.patches as mpatches\n",
    "font = {'family' : 'normal',\n",
    "        'size'   : 12}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "plt.figure(figsize=[10,6])\n",
    "\n",
    "plt.plot(n_components,np.array([i.weighted_average for i in evaluators_X]),label=\"with cross-validation\",color=\"blue\",marker='o',markersize=11,markeredgecolor=\"black\")\n",
    "plt.plot(n_components,np.array([i.weighted_average for i in evaluators_X_overfit]),label=\"without cross-validation\",color=\"orange\",marker='o',markersize=11,markeredgecolor=\"black\")\n",
    "plt.axhline(y=evaluator_Y.weighted_average,c=\"blue\",linestyle  = \"--\",label=\"stellar labels\")\n",
    "plt.axhline(y=evaluator_Y_overfit.weighted_average,c=\"orange\",linestyle  = \"--\",label=\"from stellar labels\")\n",
    "plt.ylabel(\"doppelganger rate\")\n",
    "plt.xlabel(\"PCA dimensionality\")\n",
    "plt.minorticks_on()\n",
    "\n",
    "dashed_line = mlines.Line2D([], [], color=\"black\",linestyle=\"--\",\n",
    "                          markersize=15, label='from stellar labels')\n",
    "full_line = mlines.Line2D([], [], color=\"black\",linestyle=\"-\",\n",
    "                          markersize=15, label='from spectra')\n",
    "blue_patch = mpatches.Patch(color='blue', label='with cross-validation')\n",
    "orange_patch = mpatches.Patch(color='orange', label='without cross-validation')\n",
    "\n",
    "\n",
    "plt.legend(handles=[full_line,dashed_line,blue_patch,orange_patch],frameon=False)\n",
    "#plt.legend(frameon=False)\n",
    "plt.savefig(\"../../figures/global_doppelganger.pdf\",format=\"pdf\")\n",
    "plt.ylim(0,0.06)\n",
    "#plt.title(\"Doppelganger rate per star\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine grained investigation into cluster level performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cols = 22\n",
    "fig = plt.figure(constrained_layout=True,figsize=[3*n_cols,10])\n",
    "gspec = gridspec.GridSpec(ncols=n_cols, nrows=2, figure=fig)\n",
    "#for i in range(len(sorted(spectra_evaluator.registry))):\n",
    "for i in range(n_cols):\n",
    "    spec_ax = fig.add_subplot(gspec[0, i])\n",
    "    evaluators_X[3].plot_cluster(sorted(evaluators_X[3].registry)[i],spec_ax,x_max=80)\n",
    "    abund_ax = fig.add_subplot(gspec[1, i])\n",
    "    evaluator_Y.plot_cluster(sorted(evaluator_Y.registry)[i],abund_ax,x_max=80)\n",
    "    \n",
    "#plt.savefig(\"../../figures/local_doppelganger.pdf\",format=\"pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cols = 5\n",
    "fig = plt.figure(constrained_layout=True,figsize=[4*n_cols,5])\n",
    "gspec = gridspec.GridSpec(ncols=n_cols, nrows=2, figure=fig)\n",
    "#for i in range(len(sorted(spectra_evaluator.registry))):\n",
    "for i in range(n_cols):\n",
    "    spec_ax = fig.add_subplot(gspec[0, i])\n",
    "    evaluators_X[3].plot_cluster(sorted(evaluators_X[3].registry)[i],spec_ax,x_max=30)\n",
    "    abund_ax = fig.add_subplot(gspec[1, i])\n",
    "    #abund_ax.set_xlabel(\"distance\",fontsize=20)\n",
    "    evaluator_Y.plot_cluster(sorted(evaluator_Y.registry)[i],abund_ax,x_max=40)\n",
    "    \n",
    "plt.savefig(\"../../figures/local_doppelganger0.pdf\",format=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cols = 5\n",
    "start_idx = 5\n",
    "fig = plt.figure(constrained_layout=True,figsize=[4*n_cols,5])\n",
    "gspec = gridspec.GridSpec(ncols=n_cols, nrows=2, figure=fig)\n",
    "#for i in range(len(sorted(spectra_evaluator.registry))):\n",
    "for i in range(n_cols):\n",
    "    spec_ax = fig.add_subplot(gspec[0, i])\n",
    "    evaluators_X[3].plot_cluster(sorted(evaluators_X[3].registry)[i+start_idx],spec_ax,x_max=30)\n",
    "    abund_ax = fig.add_subplot(gspec[1, i])\n",
    "    #abund_ax.set_xlabel(\"distance\",fontsize=20)\n",
    "    evaluator_Y.plot_cluster(sorted(evaluator_Y.registry)[i+start_idx],abund_ax,x_max=40)\n",
    "    \n",
    "plt.savefig(\"../../figures/local_doppelganger1.pdf\",format=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cols = 5\n",
    "start_idx = 10\n",
    "fig = plt.figure(constrained_layout=True,figsize=[4*n_cols,5])\n",
    "gspec = gridspec.GridSpec(ncols=n_cols, nrows=2, figure=fig)\n",
    "#for i in range(len(sorted(spectra_evaluator.registry))):\n",
    "for i in range(n_cols):\n",
    "    spec_ax = fig.add_subplot(gspec[0, i])\n",
    "    evaluators_X[3].plot_cluster(sorted(evaluators_X[3].registry)[i+start_idx],spec_ax,x_max=30)\n",
    "    abund_ax = fig.add_subplot(gspec[1, i])\n",
    "    #abund_ax.set_xlabel(\"distance\",fontsize=20)\n",
    "    evaluator_Y.plot_cluster(sorted(evaluator_Y.registry)[i+start_idx],abund_ax,x_max=40)\n",
    "    \n",
    "plt.savefig(\"../../figures/local_doppelganger2.pdf\",format=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cols = 5\n",
    "start_idx = 15\n",
    "fig = plt.figure(constrained_layout=True,figsize=[4*n_cols,5])\n",
    "gspec = gridspec.GridSpec(ncols=n_cols, nrows=2, figure=fig)\n",
    "#for i in range(len(sorted(spectra_evaluator.registry))):\n",
    "for i in range(n_cols):\n",
    "    spec_ax = fig.add_subplot(gspec[0, i])\n",
    "    evaluators_X[3].plot_cluster(sorted(evaluators_X[3].registry)[i+start_idx],spec_ax,x_max=30)\n",
    "    abund_ax = fig.add_subplot(gspec[1, i])\n",
    "    #abund_ax.set_xlabel(\"distance\",fontsize=20)\n",
    "    evaluator_Y.plot_cluster(sorted(evaluator_Y.registry)[i+start_idx],abund_ax,x_max=40)\n",
    "    \n",
    "plt.savefig(\"../../figures/local_doppelganger3.pdf\",format=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cols = 5\n",
    "start_idx = 20\n",
    "fig = plt.figure(constrained_layout=True,figsize=[4*n_cols,5])\n",
    "gspec = gridspec.GridSpec(ncols=n_cols, nrows=2, figure=fig)\n",
    "#for i in range(len(sorted(spectra_evaluator.registry))):\n",
    "for i in range(2):\n",
    "    spec_ax = fig.add_subplot(gspec[0, i])\n",
    "    evaluators_X[3].plot_cluster(sorted(evaluators_X[3].registry)[i+start_idx],spec_ax,x_max=30)\n",
    "    abund_ax = fig.add_subplot(gspec[1, i])\n",
    "    #abund_ax.set_xlabel(\"distance\",fontsize=20)\n",
    "    evaluator_Y.plot_cluster(sorted(evaluator_Y.registry)[i+start_idx],abund_ax,x_max=40)\n",
    "    \n",
    "plt.savefig(\"../../figures/local_doppelganger4.pdf\",format=\"pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting performance against open clusters\n",
    "\n",
    "We plot the performance obtained against the number of open-clusters used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_repeats = 5 #How many different combinations of clusters to sample for each size\n",
    "n_clusters_considered = [10,15,20,22] #How many clusters to preserve\n",
    "n_component = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_random_clusters(vector_occam,n_clusters):\n",
    "    cluster_list = random.sample(list(vector_occam.registry),n_clusters)\n",
    "    return vector_occam.only(cluster_list)\n",
    "\n",
    "def make_doppelganger_vs_clusters(n_clusters_considered,X,X_occam,n_repeats):\n",
    "    \"\"\"\n",
    "    Calculate the average doppelganger rate for a given number of clusters\n",
    "    -------------------------------\n",
    "    n_clusters_considered: list\n",
    "            cluster sizes to calculate for\n",
    "    X: vector.Vector\n",
    "        X dataset\n",
    "    X_occam:vector.OccamVector\n",
    "        X_dataset\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    for n_clusters in n_clusters_considered:\n",
    "        res.append([])\n",
    "        for _ in range(n_repeats):\n",
    "            X_restricted = get_n_random_clusters(X_occam,n_clusters)\n",
    "            evaluator_X = evaluators.StandardEvaluator(X,X_restricted,leave_out=True,fitter_class=standard_fitter)\n",
    "            res[-1].append(evaluator_X.weighted_average)  \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dim = 15\n",
    "res_X15 = make_doppelganger_vs_clusters(n_clusters_considered,Z[:,:n_dim],Z_occam[:,:n_dim],n_repeats)\n",
    "n_dim = 25\n",
    "res_X25 = make_doppelganger_vs_clusters(n_clusters_considered,Z[:,:n_dim],Z_occam[:,:n_dim],n_repeats)\n",
    "n_dim = 35\n",
    "res_X35 = make_doppelganger_vs_clusters(n_clusters_considered,Z[:,:n_dim],Z_occam[:,:n_dim],n_repeats)\n",
    "res_Y = make_doppelganger_vs_clusters(n_clusters_considered,Y,Y_occam,n_repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[8,6])\n",
    "plt.plot(np.array(n_clusters_considered)-1,[np.mean(res_i) for res_i in res_X35],label=\"spectra 35\",color=\"blue\",marker='o',markersize=11,markeredgecolor=\"black\")\n",
    "plt.plot(np.array(n_clusters_considered)-1,[np.mean(res_i) for res_i in res_X25],label=\"spectra 25\",color=\"purple\",marker='o',markersize=11,markeredgecolor=\"black\")\n",
    "plt.plot(np.array(n_clusters_considered)-1,[np.mean(res_i) for res_i in res_X15],label=\"spectra 15\",color=\"black\",marker='o',markersize=11,markeredgecolor=\"black\")\n",
    "\n",
    "plt.plot(np.array(n_clusters_considered)-1,[np.mean(res_i) for res_i in res_Y],label=\"labels\",color=\"orange\",marker='o',markersize=11,markeredgecolor=\"black\")\n",
    "plt.minorticks_on()\n",
    "#np.array(n_clusters_considered)-1 because one cluster removed from scaling when evaluated on leave-out=True \n",
    "\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.ylabel(\"Doppelganger rate\")\n",
    "plt.ylim(0.,0.06)\n",
    "plt.legend(frameon=False)\n",
    "plt.savefig(\"../../figures/doppelganger_vs_clusters.pdf\",format=\"pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting performance against dataset size\n",
    "\n",
    "We investigate how much the PCA compression is affected by the dataset size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Zs(data,data_occam,d,tol,n_stars = 1000):\n",
    "    kept_idxs = np.random.choice(len(data.masked_spectra),n_stars,replace=False)\n",
    "    #z,z_occam,ppca = fitters.compress_masked_spectra(data.masked_spectra[kept_idxs],data_occam.masked_spectra,d,tol=tol)\n",
    "    z,z_occam,ppca = fitters.compress_masked_spectra(data.masked_spectra[kept_idxs][:,mask_interstellar],data_occam.masked_spectra[:,mask_interstellar],d,tol=tol)\n",
    "\n",
    "    Z_occam = vectors.OccamVector(val = z_occam,cluster_names=cluster_idxs).remove_orphans()\n",
    "    Z = vectors.Vector(val = z)\n",
    "    return Z,Z_occam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = [10000,30000,50000]\n",
    "n_repeats = 10\n",
    "d=35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(5):\n",
    "    Z,Z_occam = get_Zs(data_occamlike,data_occam,d=d,tol=0.1,n_stars = 30000)\n",
    "\n",
    "    evaluator.weighted_average\n",
    "    print(f\"weighted_average:{evaluator.weighted_average}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z,Z_occam = get_Zs(data_occamlike,data_occam,d=d,tol=0.01,n_stars = 50000)\n",
    "evaluator = evaluators.StandardEvaluator(Z,Z_occam,leave_out=True,fitter_class=standard_fitter)\n",
    "evaluator.weighted_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_datasize = []\n",
    "for dataset_size in dataset_sizes:\n",
    "    res_datasize.append([])\n",
    "    for _ in range(n_repeats):\n",
    "        Z,Z_occam = get_Zs(data_occamlike,data_occam,d=d,tol=0.1,n_stars = dataset_size)\n",
    "        evaluator = evaluators.StandardEvaluator(Z,Z_occam,leave_out=True,fitter_class=standard_fitter)\n",
    "        res_datasize[-1].append(evaluator.weighted_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(dataset_sizes,np.mean(np.array(res_datasize),axis=1))\n",
    "plt.xlabel(r\"size $X_{pop}$\")\n",
    "plt.ylabel(\"doppelganger rate\")\n",
    "plt.savefig(\"../../figures/doppelganger_vs_Xsize.pdf\",format=\"pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_datasize[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kept_idxs = np.random.choice(len(data_occamlike.masked_spectra),100,replace=False)\n",
    "kept_idxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure correlation between similarity and other parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_ij(i,j,v):\n",
    "    return np.linalg.norm(v[i]-v[j])\n",
    "\n",
    "def get_similarity(X,Y,n_repeats=50000,n_max=10000,use_delta=True):\n",
    "    \"\"\"\n",
    "    OUTPUTS\n",
    "    -------\n",
    "    similarity_list: \n",
    "        contains the chemical similarity for random pairs of stars\n",
    "    delta_list:\n",
    "        contains the difference in variable of interest for these same stars\n",
    "    use_delta: boolean\n",
    "        if true give the difference between two varialbles. If false give the average.\n",
    "    \"\"\"\n",
    "    similarity_list = []\n",
    "    delta_list = []\n",
    "    for _ in range(n_repeats):\n",
    "        i,j = np.random.choice(n_max,2)\n",
    "        if  (Y[i]>-100) and (Y[j]>-100):\n",
    "            similarity_list.append(similarity_ij(i,j,X))\n",
    "            if use_delta is True:\n",
    "                delta_list.append(np.abs(Y[i]-Y[j]))\n",
    "            else:\n",
    "                delta_list.append(np.mean([Y[i],Y[j]]))\n",
    "    return similarity_list,delta_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the transformed representation on which metric leraning is applied\n",
    "\n",
    "z,z_occam,ppca = fitters.compress_masked_spectra(data_occamlike.masked_spectra,data_occam.masked_spectra,d,tol=tol)\n",
    "Z_occam = vectors.OccamVector(val = z_occam,cluster_names=cluster_idxs).remove_orphans()\n",
    "Z = vectors.Vector(val = z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dim = 30\n",
    "ev_x = evaluators.StandardEvaluator(Z[:,:z_dim],Z_occam[:,:z_dim],leave_out=True,fitter_class=standard_fitter)\n",
    "ev_x.weighted_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y_fitter = standard_fitter(Y,Y_occam)\n",
    "v_y = Y_fitter.transform(Y.centered(Y_occam)).val\n",
    "\n",
    "##########################################################\n",
    "\n",
    "z_dim = 30\n",
    "Z_fitter = standard_fitter(Z[:,:z_dim],Z_occam[:,:z_dim])\n",
    "v_z = Z_fitter.transform(Z_fitter.z.centered(Z_occam[:,:z_dim])).val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#param = \"AK_TARG\"\n",
    "param = \"SNR\"\n",
    "y_interest = allStar_occamlike[n_start:n_start+n_stars][param]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zs,delta_zs = get_similarity(v_z,y_interest)\n",
    "ys,delta_ys = get_similarity(v_y,y_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap,xedges,yedges = np.histogram2d(delta_zs,zs,bins=[80,80])\n",
    "extent = [xedges[0], xedges[-1], yedges[0], yedges[-1]]\n",
    "plt.clf()\n",
    "plt.imshow(heatmap.T,extent=extent,origin='lower',cmap=\"Greens\",aspect=0.01)\n",
    "plt.plot(delta_zs,np.poly1d(np.polyfit(delta_zs, zs, 1))(delta_zs),color=\"orange\",label=\"from spectra\")\n",
    "plt.plot(delta_ys,np.poly1d(np.polyfit(delta_ys, ys, 1))(delta_ys),color=\"blue\",label=\"from labels\")\n",
    "plt.legend(frameon=False)\n",
    "plt.xlim(0,0.5)\n",
    "plt.ylim(0,40)\n",
    "plt.ylabel(\"similarity\")\n",
    "plt.xlabel(rf\"$\\Delta$ {param}\")\n",
    "plt.colorbar(label=\"density\")\n",
    "plt.savefig(\"../../figures/extinction_trend_before.pdf\",format=\"pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_zs= zs/np.mean(zs)\n",
    "norm_ys= ys/np.mean(ys)\n",
    "heatmap,xedges,yedges = np.histogram2d(delta_zs,norm_zs,bins=[80,80])\n",
    "extent = [xedges[0], xedges[-1], yedges[0], yedges[-1]]\n",
    "plt.clf()\n",
    "plt.imshow(heatmap.T,extent=extent,origin='lower',cmap=\"Greens\",aspect=0.2)\n",
    "plt.plot(delta_zs,np.poly1d(np.polyfit(delta_zs, norm_zs, 1))(delta_zs),color=\"orange\",label=\"from spectra\")\n",
    "plt.plot(delta_ys,np.poly1d(np.polyfit(delta_ys, norm_ys, 1))(delta_ys),color=\"blue\",label=\"from labels\")\n",
    "plt.legend(frameon=False)\n",
    "plt.xlim(0,0.5)\n",
    "plt.ylim(0,2)\n",
    "plt.ylabel(\"similarity\")\n",
    "plt.xlabel(rf\"$\\Delta$ {param}\")\n",
    "plt.colorbar(label=\"density\")\n",
    "plt.savefig(\"../../figures/extinction_trend_after.pdf\",format=\"pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z,z_occam,ppca = fitters.compress_masked_spectra(data_occamlike.masked_spectra[:,mask_interstellar],data_occam.masked_spectra[:,mask_interstellar],d,tol=tol)\n",
    "Z_occam = vectors.OccamVector(val = z_occam,cluster_names=cluster_idxs).remove_orphans()\n",
    "Z = vectors.Vector(val = z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev_x = evaluators.StandardEvaluator(Z[:,:z_dim],Z_occam[:,:z_dim],leave_out=True,fitter_class=standard_fitter)\n",
    "ev_x.weighted_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_fitter = standard_fitter(Y,Y_occam)\n",
    "v_y = Y_fitter.transform(Y.centered(Y_occam)).val\n",
    "\n",
    "##########################################################\n",
    "\n",
    "z_dim = 30\n",
    "Z_fitter = standard_fitter(Z[:,:z_dim],Z_occam[:,:z_dim])\n",
    "v_z = Z_fitter.transform(Z_fitter.z.centered(Z_occam[:,:z_dim])).val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zs,delta_zs = get_similarity(v_z,y_interest,use_delta=False)\n",
    "ys,delta_ys = get_similarity(v_y,y_interest,use_delta=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap,xedges,yedges = np.histogram2d(delta_zs,zs,bins=[80,80])\n",
    "extent = [xedges[0], xedges[-1], yedges[0], yedges[-1]]\n",
    "plt.clf()\n",
    "plt.imshow(heatmap.T,extent=extent,origin='lower',cmap=\"Greens\",aspect=0.01)\n",
    "plt.plot(delta_zs,np.poly1d(np.polyfit(delta_zs, zs, 1))(delta_zs),color=\"orange\",label=\"from spectra\")\n",
    "plt.plot(delta_ys,np.poly1d(np.polyfit(delta_ys, ys, 1))(delta_ys),color=\"blue\",label=\"from labels\")\n",
    "plt.legend(frameon=False)\n",
    "plt.xlim(0,0.5)\n",
    "plt.ylim(0,40)\n",
    "plt.ylabel(\"similarity\")\n",
    "plt.xlabel(rf\"$\\Delta$ {param}\")\n",
    "plt.colorbar(label=\"density\")\n",
    "#plt.savefig(\"../../figures/extinction_trend_after.pdf\",format=\"pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_zs= zs/np.mean(zs)\n",
    "norm_ys= ys/np.mean(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap,xedges,yedges = np.histogram2d(delta_zs,norm_zs,bins=[80,80])\n",
    "extent = [xedges[0], xedges[-1], yedges[0], yedges[-1]]\n",
    "plt.clf()\n",
    "plt.imshow(heatmap.T,extent=extent,origin='lower',cmap=\"Greens\",aspect=0.2)\n",
    "plt.plot(delta_zs,np.poly1d(np.polyfit(delta_zs, norm_zs, 1))(delta_zs),color=\"orange\",label=\"from spectra\")\n",
    "plt.plot(delta_ys,np.poly1d(np.polyfit(delta_ys, norm_ys, 1))(delta_ys),color=\"blue\",label=\"from labels\")\n",
    "plt.legend(frameon=False)\n",
    "plt.xlim(0,0.5)\n",
    "plt.ylim(0,2)\n",
    "plt.ylabel(\"similarity\")\n",
    "plt.xlabel(rf\"$\\Delta$ {param}\")\n",
    "plt.colorbar(label=\"density\")\n",
    "#plt.savefig(\"../../figures/extinction_trend_after.pdf\",format=\"pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap,xedges,yedges = np.histogram2d(delta_zs,norm_zs,bins=[50,50])\n",
    "extent = [xedges[0], xedges[-1], yedges[0], yedges[-1]]\n",
    "plt.clf()\n",
    "plt.imshow(heatmap.T,extent=extent,origin='lower',cmap=\"Greens\",aspect=400.)\n",
    "plt.plot(delta_zs,np.poly1d(np.polyfit(delta_zs, norm_zs, 1))(delta_zs),color=\"orange\",label=\"from spectra\")\n",
    "plt.plot(delta_ys,np.poly1d(np.polyfit(delta_ys, norm_ys, 1))(delta_ys),color=\"blue\",label=\"from labels\")\n",
    "plt.legend(frameon=False)\n",
    "plt.xlim(0,300)\n",
    "plt.ylim(0,2)\n",
    "\n",
    "plt.ylabel(\"similarity\")\n",
    "plt.xlabel(rf\"$\\Delta$ {param}\")\n",
    "plt.colorbar(label=\"density\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(delta_zs)\n",
    "plt.xlim(0,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_interest)\n",
    "plt.xlim(0,500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sandbox exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allStar[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_Y.doppelganger_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(evaluator_Y.registry)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = evaluator_Y #evaluator_Y #evaluators_X[3] #evaluators_X[3] #evaluator_Y\n",
    "clust_dopps = []\n",
    "clust_mean_fes = []\n",
    "len_clusts = []\n",
    "for i in range(len(Y_occam.registry)):\n",
    "    clust_dopp = evaluator.doppelganger_rates[i]\n",
    "    clust_mean_fe = np.mean(Y_occam.only(sorted(evaluator.registry)[i]).val[:,0])\n",
    "    clust_mean_fes.append(clust_mean_fe)\n",
    "    clust_dopps.append(clust_dopp)\n",
    "    len_clusts.append(len(Y_occam.only(sorted(evaluator.registry)[i]).val[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clust_dopps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(len_clusts,clust_dopps)\n",
    "for i, txt in enumerate(sorted(evaluator.registry)):\n",
    "    plt.annotate(txt, (len_clusts[i], clust_dopps[i]),fontsize=8)\n",
    "plt.xlabel(\"cluster size\")\n",
    "plt.ylabel(\"doppelganger rate\")\n",
    "\n",
    "plt.title(\"from spectra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(len_clusts,clust_dopps)\n",
    "for i, txt in enumerate(sorted(evaluator.registry)):\n",
    "    plt.annotate(txt, (len_clusts[i], clust_dopps[i]),fontsize=8)\n",
    "plt.xlabel(\"cluster size\")\n",
    "plt.ylabel(\"doppelganger rate\")\n",
    "\n",
    "plt.title(\"from label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(len_clusts,clust_dopps)\n",
    "for i, txt in enumerate(sorted(evaluator.registry)):\n",
    "    plt.annotate(txt, (len_clusts[i], clust_dopps[i]),fontsize=8)\n",
    "#plt.ylim(-0.01,0.05)\n",
    "plt.title(\"from spectra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(clust_mean_fes,clust_dopps)\n",
    "#plt.ylim(-0.01,0.03)\n",
    "for i, txt in enumerate(sorted(evaluator.registry)):\n",
    "    plt.annotate(txt, (clust_mean_fes[i], clust_dopps[i]),fontsize=8)\n",
    "\n",
    "plt.title(\"from labels\")\n",
    "plt.xlabel(\"Fe_H\")\n",
    "plt.ylabel(\"doppelganger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(clust_mean_fes,clust_dopps)\n",
    "for i, txt in enumerate(sorted(evaluator.registry)):\n",
    "    plt.annotate(txt, (clust_mean_fes[i], clust_dopps[i]),fontsize=8)\n",
    "plt.ylim(-0.01,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(clust_mean_fes,clust_dopps)\n",
    "for i, txt in enumerate(sorted(evaluator.registry)):\n",
    "    plt.annotate(txt, (clust_mean_fes[i], clust_dopps[i]),fontsize=8)\n",
    "plt.ylim(-0.01,0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(Y_occam.only(sorted(evaluator_Y.registry)[i]).val[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_occam.only(sorted(evaluator_Y.registry)[i]).val[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluators_X[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([5,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taggenv",
   "language": "python",
   "name": "taggenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
